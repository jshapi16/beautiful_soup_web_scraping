{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Driver [/Users/jds/.wdm/drivers/chromedriver/mac64/91.0.4472.101/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "#set up executable path\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape news from redplanet website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup beautiful soup for redplanetscience.com\n",
    "\n",
    "#URL to be scraped\n",
    "url = \"https://www.redplanetscience.com\"\n",
    "\n",
    "#visit url\n",
    "browser.visit(url)\n",
    "\n",
    "#Grab the html \n",
    "news_html = browser.html\n",
    "\n",
    "#create beautiful soup object with parser - parse in the html elements\n",
    "soup = BeautifulSoup(news_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"NASA's Treasure Map for Water Ice on Mars\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find most recent news title\n",
    "news_title = soup.find('div', class_=\"content_title\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A new study identifies frozen water just below the Martian surface, where astronauts could easily dig it up.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find paragraph text\n",
    "news_p = soup.find('div', class_=\"article_teaser_body\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape photo from mars space image website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featured_image_url():\n",
    "    url=\"https://spaceimages-mars.com/\"\n",
    "    html = browser.visit(url)\n",
    "    #locate the button and click it\n",
    "    image_element = browser.find_by_tag(\"button\")[1]\n",
    "    image_element.click()\n",
    "    #Parse with beautiful soup\n",
    "    html = browser.html\n",
    "    img_soup = BeautifulSoup(html, 'html.parser')\n",
    "    #Select image src and add it to the url\n",
    "    image_anchor = img_soup.find(\"img\", class_=\"fancybox-image\").get('src')\n",
    "    featured_image_url = url + image_anchor\n",
    "    return featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape hemisphere data from mars hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_hemispheres():\n",
    "    #Visit mars hemispheres website\n",
    "    url = 'https://marshemispheres.com/'\n",
    "    browser.visit(url)\n",
    "    hemisphere_image_links = []\n",
    "\n",
    "    #get links for all hemispheres\n",
    "    links = browser.find_by_css('a.product-item img')\n",
    "    hemisphere_dict = {}\n",
    "\n",
    "    #click all links and get the href\n",
    "    for i in range(len(links)):\n",
    "        browser.find_by_css('a.product-item img')[i].click()\n",
    "        thumb_img = browser.links.find_by_text('Sample').first\n",
    "        print(thumb_img)\n",
    "\n",
    "        #hemisphere href\n",
    "        hemisphere_dict['img_url'] = thumb_img['href']\n",
    "\n",
    "        #hemisphere title\n",
    "        hemisphere_dict['title'] = browser.find_by_css('h2.title').text\n",
    "\n",
    "        hemisphere_image_links.append(hemisphere_dict)\n",
    "\n",
    "        browser.back()\n",
    "    return hemisphere_image_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all():\n",
    "    executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "    browser = Browser('chrome', **executable_path, headless=True)\n",
    "    \n",
    "    #Redplanetscience\n",
    "    #URL to be scraped\n",
    "    url = \"https://www.redplanetscience.com\"\n",
    "    #visit url\n",
    "    browser.visit(url)\n",
    "    #Grab the html \n",
    "    news_html = browser.html\n",
    "    #create beautiful soup object with parser - parse in the html elements\n",
    "    soup = BeautifulSoup(news_html, \"html.parser\")\n",
    "    #find most recent news title\n",
    "    news_title = soup.find('div', class_=\"content_title\").text\n",
    "    #find paragraph text\n",
    "    news_p = soup.find('div', class_=\"article_teaser_body\").text\n",
    "    \n",
    "    \n",
    "    #Space images, featured image \n",
    "    url=\"https://spaceimages-mars.com/\"\n",
    "    html = browser.visit(url)\n",
    "    #locate the button and click it\n",
    "    image_element = browser.find_by_tag(\"button\")[1]\n",
    "    image_element.click()\n",
    "    #Parse with beautiful soup\n",
    "    html = browser.html\n",
    "    img_soup = BeautifulSoup(html, 'html.parser')\n",
    "    #Select image src and add it to the url\n",
    "    image_anchor = img_soup.find(\"img\", class_=\"fancybox-image\").get('src')\n",
    "    featured_image_url = url + image_anchor\n",
    "    \n",
    "    def mars_facts():\n",
    "        mars_table = pd.read_html('https://galaxyfacts-mars.com')[0]\n",
    "        mars_table.columns = ['description', 'mars', 'earth']\n",
    "        mars_table.set_index('description', inplace=True)\n",
    "        mars_df = mars_table.to_html()\n",
    "        return mars_df\n",
    "\n",
    "    #mars hemispheres information\n",
    "    def mars_hemispheres():\n",
    "        #Visit mars hemispheres website\n",
    "        url = 'https://marshemispheres.com/'\n",
    "        browser.visit(url)\n",
    "        hemisphere_image_links = []\n",
    "\n",
    "        #get links for all hemispheres\n",
    "        links = browser.find_by_css('a.product-item img')\n",
    "        hemisphere_dict = {}\n",
    "        #click all links and get the href\n",
    "        for i in range(len(links)):\n",
    "            browser.find_by_css('a.product-item img')[i].click()\n",
    "            thumb_img = browser.links.find_by_text('Sample').first\n",
    "            print(thumb_img)\n",
    "            #hemisphere href\n",
    "            hemisphere_dict['img_url'] = thumb_img['href']\n",
    "            #hemisphere title\n",
    "            hemisphere_dict['title'] = browser.find_by_css('h2.title').text\n",
    "            hemisphere_image_links.append(hemisphere_dict)\n",
    "            browser.back()\n",
    "        return hemisphere_image_links\n",
    "\n",
    "    mars_data = {\n",
    "        \"news_title\": news_title,\n",
    "        \"news_p\": news_p,\n",
    "        \"featured_image\": featured_image_url(browser),\n",
    "        \"hemispheres\": mars_hemispheres(browser),\n",
    "    }\n",
    "    browser.quit()\n",
    "    return(mars_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
